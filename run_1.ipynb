{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os       \n",
    "os.chdir('/workspace/my_cyclegan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --norm instance\\\n",
    "# --init_type xavier\\\n",
    "# --num_iter_gen 1\\\n",
    "# --gan_mode lsgan\\\n",
    "# --upsampling_type transpose\\\n",
    "# --n_blocks 9\\\n",
    "# --n_downsampling 2\\\n",
    "# --ngf_depth 32\\\n",
    "# --ngf_img 32\\\n",
    "# --ndf 64\\\n",
    "# --netD n_layers\\\n",
    "# --n_layers_D 3\\\n",
    "# --continue_train\\\n",
    "# --load_epoch 6\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 16                            \t[default: 5]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "             data_shuffle: True                          \t[default: False]\n",
      "                 dataroot: /all_data/hdd/un_depth/semi/sample\n",
      "             dataset_mode: semi_cycle                    \n",
      "            deterministic: False                         \n",
      "           disc_for_depth: False                         \n",
      "         disc_for_normals: False                         \n",
      "                  dropout: False                         \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0,1                           \n",
      "                 img_freq: 40                            \t[default: 1]\n",
      "                init_type: xavier                        \n",
      "           input_nc_depth: 1                             \n",
      "             input_nc_img: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "               load_epoch: last                          \n",
      "       load_epoch_weights: last                          \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "              load_size_h: 480                           \n",
      "              load_size_w: 640                           \n",
      "                loss_freq: 30                            \t[default: 1]\n",
      "                     lr_D: 0.0002                        \n",
      "                     lr_G: 0.0002                        \n",
      "                   lr_G_A: 0.0001                        \n",
      "                   lr_G_B: 0.0001                        \t[default: 0.0005]\n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: 20000                         \t[default: inf]\n",
      "             max_distance: 8000.0                        \n",
      "                    model: pretrain                      \t[default: semi_cycle_gan]\n",
      "                 n_blocks: 9                             \n",
      "           n_downsampling: 2                             \n",
      "                 n_epochs: 10                            \t[default: 1]\n",
      "           n_epochs_decay: 5                             \t[default: 1]\n",
      "               n_layers_D: 3                             \n",
      "                    n_pic: 3                             \n",
      "                     name: pretrain_weights_batch_norms  \t[default: test]\n",
      "                      ndf: 64                            \n",
      "                     netD: n_layers                      \n",
      "                ngf_depth: 32                            \n",
      "                  ngf_img: 32                            \n",
      "                     norm: instance                      \n",
      "              num_workers: 4                             \n",
      "          output_nc_depth: 1                             \n",
      "            output_nc_img: 41                            \n",
      "                    phase: train                         \n",
      "          save_epoch_freq: 10                            \n",
      "          upsampling_type: transpose                     \n",
      "        use_mean_matching: False                         \n",
      "      use_petrain_weights: False                         \n",
      "         use_second_cycle: False                         \n",
      "             use_semantic: False                         \n",
      "           use_semi_cycle: False                         \n",
      "                  verbose: False                         \n",
      "              weights_dir: ./checkpoints/pretrain_weights/\n",
      "----------------- End -------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201111_074506-pa8vwb3b\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpretrain_weights_batch_norms\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/maxs/depth_super_res\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/maxs/depth_super_res/runs/pa8vwb3b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Dataset SemiCycleDataset was created\n",
      "The number of training images = 20000\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "model [PreTrainModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network netG_A] Total number of parameters : 11.620 M\n",
      "[Network netG_B] Total number of parameters : 11.620 M\n",
      "-----------------------------------------------\n",
      "640 img procesed out of 20000, taken 0.79 sec per 1 batch\n",
      "1280 img procesed out of 20000, taken 0.80 sec per 1 batch\n",
      "1920 img procesed out of 20000, taken 0.80 sec per 1 batch\n",
      "2560 img procesed out of 20000, taken 0.85 sec per 1 batch\n",
      "3200 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "3840 img procesed out of 20000, taken 0.84 sec per 1 batch\n",
      "4480 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "5120 img procesed out of 20000, taken 0.86 sec per 1 batch\n",
      "5760 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "6400 img procesed out of 20000, taken 0.86 sec per 1 batch\n",
      "7040 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "7680 img procesed out of 20000, taken 0.86 sec per 1 batch\n",
      "8320 img procesed out of 20000, taken 0.79 sec per 1 batch\n",
      "8960 img procesed out of 20000, taken 0.84 sec per 1 batch\n",
      "9600 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "10240 img procesed out of 20000, taken 0.88 sec per 1 batch\n",
      "10880 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "11520 img procesed out of 20000, taken 0.85 sec per 1 batch\n",
      "12160 img procesed out of 20000, taken 0.87 sec per 1 batch\n",
      "12800 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "13440 img procesed out of 20000, taken 0.87 sec per 1 batch\n",
      "14080 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "14720 img procesed out of 20000, taken 0.85 sec per 1 batch\n",
      "15360 img procesed out of 20000, taken 0.86 sec per 1 batch\n",
      "16000 img procesed out of 20000, taken 0.91 sec per 1 batch\n",
      "16640 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "17280 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "17920 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "18560 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "19200 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "19840 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "End of epoch 1 / 15 \t Time Taken: 1155.84 sec\n",
      "learning rate = 0.0001000\n",
      "480 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "1120 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "1760 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "2400 img procesed out of 20000, taken 0.79 sec per 1 batch\n",
      "3040 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "3680 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "4320 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "4960 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "5600 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "6240 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "6880 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "7520 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "8160 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "8800 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "9440 img procesed out of 20000, taken 0.79 sec per 1 batch\n",
      "10080 img procesed out of 20000, taken 0.79 sec per 1 batch\n",
      "10720 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "11360 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "12000 img procesed out of 20000, taken 0.90 sec per 1 batch\n",
      "12640 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "13280 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "13920 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "14560 img procesed out of 20000, taken 0.78 sec per 1 batch\n",
      "Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 890, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workspace/my_cyclegan/models/network.py\", line 645, in forward\n",
      "    x = self.bottlenec(depth, img)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workspace/my_cyclegan/models/network.py\", line 589, in forward\n",
      "    return self.model(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workspace/my_cyclegan/models/network.py\", line 612, in forward\n",
      "    out = x + self.conv_block(x)  # add skip connections\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 100, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 353, in forward\n",
      "    return self._conv_forward(input, self.weight)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 348, in _conv_forward\n",
      "    _pair(0), self.dilation, self.groups)\n",
      " (print_stack at /opt/conda/conda-bld/pytorch_1591914855613/work/torch/csrc/autograd/python_anomaly_mode.cpp:60)\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 46, in <module>\n",
      "    model.optimize_param()\n",
      "  File \"/workspace/my_cyclegan/models/pretrain.py\", line 73, in optimize_param\n",
      "    self.backward_G()\n",
      "  File \"/workspace/my_cyclegan/models/pretrain.py\", line 68, in backward_G\n",
      "    self.loss_G.backward()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/tensor.py\", line 198, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 100, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "RuntimeError: Function 'CudnnConvolutionBackward' returned nan values in its 1th output.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 13263\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1. Press ctrl-c to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                      depth_dif_B 0.16295063495635986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                         _runtime 2024.9497230052948\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                      depth_dif_A 0.13791467249393463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                       norm_dif_B 0.024859195575118065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                       norm_dif_A 0.04083982855081558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            _step 2160\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                       _timestamp 1605082730.0531452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 5 W&B file(s), 55 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced pretrain_weights_batch_norms: https://app.wandb.ai/maxs/depth_super_res/runs/pa8vwb3b\n"
     ]
    }
   ],
   "source": [
    "!python train.py --name pretrain_weights_batch_norms\\\n",
    "--model pretrain\\\n",
    "--gpu_ids 0,1\\\n",
    "--batch_size 16\\\n",
    "--max_dataset_size 20000\\\n",
    "--data_shuffle\\\n",
    "--lr_G_A 0.0001\\\n",
    "--lr_G_B 0.0001\\\n",
    "--img_freq 40\\\n",
    "--loss_freq 30\\\n",
    "--save_epoch_freq 10\\\n",
    "--n_epochs 10\\\n",
    "--n_epochs_decay 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 8                             \t[default: 5]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "             data_shuffle: True                          \t[default: False]\n",
      "                 dataroot: /all_data/hdd/un_depth/semi/sample\n",
      "             dataset_mode: semi_cycle                    \n",
      "            deterministic: False                         \n",
      "           disc_for_depth: True                          \t[default: False]\n",
      "         disc_for_normals: False                         \n",
      "                  dropout: False                         \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0,1                           \n",
      "                 img_freq: 40                            \t[default: 1]\n",
      "                init_type: xavier                        \n",
      "           input_nc_depth: 1                             \n",
      "             input_nc_img: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "          l_cycle_A_begin: 10.0                          \n",
      "            l_cycle_A_end: 10.0                          \n",
      "          l_cycle_B_begin: 10.0                          \n",
      "            l_cycle_B_end: 10.0                          \n",
      "          l_depth_A_begin: 0.0                           \t[default: 5.0]\n",
      "            l_depth_A_end: 0.0                           \n",
      "          l_depth_B_begin: 0.0                           \t[default: 5.0]\n",
      "            l_depth_B_end: 0.0                           \n",
      "         l_depth_max_iter: 10000                         \t[default: 5000]\n",
      "               l_identity: 5.0                           \t[default: 0.0]\n",
      "l_reconstruction_semantic: 0.0                           \n",
      "               load_epoch: last                          \n",
      "       load_epoch_weights: last                          \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "              load_size_h: 480                           \n",
      "              load_size_w: 640                           \n",
      "                loss_freq: 30                            \t[default: 1]\n",
      "                     lr_D: 0.0002                        \n",
      "                     lr_G: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: 20000                         \t[default: inf]\n",
      "             max_distance: 8000.0                        \n",
      "                   mean_A: 1680.1208394737955            \n",
      "                   mean_B: 2781.0011373752295            \n",
      "                    model: semi_cycle_gan                \n",
      "                 n_blocks: 9                             \n",
      "           n_downsampling: 2                             \n",
      "                 n_epochs: 10                            \t[default: 1]\n",
      "           n_epochs_decay: 5                             \t[default: 1]\n",
      "               n_layers_D: 3                             \n",
      "                    n_pic: 3                             \n",
      "                     name: mean_unoformstd_weights_synimg\t[default: test]\n",
      "                      ndf: 64                            \n",
      "                     netD: n_layers                      \n",
      "                ngf_depth: 32                            \n",
      "                  ngf_img: 32                            \n",
      "                     norm: instance                      \n",
      "             num_iter_dis: 1                             \n",
      "             num_iter_gen: 1                             \n",
      "              num_workers: 4                             \n",
      "          output_nc_depth: 1                             \n",
      "            output_nc_img: 41                            \n",
      "                    phase: train                         \n",
      "          save_epoch_freq: 10                            \n",
      "                    std_A: 487.0543836544621             \n",
      "                    std_B: 780.4723869231325             \n",
      "          upsampling_type: transpose                     \t[default: upconv]\n",
      "                 use_blur: False                         \n",
      "        use_mean_matching: True                          \t[default: False]\n",
      "      use_petrain_weights: True                          \t[default: False]\n",
      "         use_second_cycle: True                          \t[default: False]\n",
      "             use_semantic: False                         \n",
      "           use_semi_cycle: False                         \n",
      "                  verbose: False                         \n",
      "              weights_dir: ./checkpoints/pretrain_weights_synimg/\t[default: ./checkpoints/pretrain_weights/]\n",
      "----------------- End -------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201110_084757-25z6cibs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmean_unoformstd_weights_synimg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/maxs/depth_super_res\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/maxs/depth_super_res/runs/25z6cibs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Dataset SemiCycleDataset was created\n",
      "The number of training images = 20000\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "model [SemiCycleGANModel] was created\n",
      "loading the model from ./checkpoints/pretrain_weights_synimg/last.pt\n",
      "loading the model from ./checkpoints/pretrain_weights_synimg/last.pt\n",
      "---------- Networks initialized -------------\n",
      "[Network netG_A] Total number of parameters : 11.615 M\n",
      "[Network netG_B] Total number of parameters : 11.615 M\n",
      "[Network netD_A_depth] Total number of parameters : 2.763 M\n",
      "[Network netD_B_depth] Total number of parameters : 2.763 M\n",
      "-----------------------------------------------\n",
      "320 img procesed out of 20000, taken 1.02 sec per 1 batch\n",
      "640 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "960 img procesed out of 20000, taken 1.02 sec per 1 batch\n",
      "1280 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "1600 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "1920 img procesed out of 20000, taken 1.02 sec per 1 batch\n",
      "2240 img procesed out of 20000, taken 1.02 sec per 1 batch\n",
      "2560 img procesed out of 20000, taken 1.02 sec per 1 batch\n",
      "2880 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "3200 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "3520 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "3840 img procesed out of 20000, taken 1.02 sec per 1 batch\n",
      "4160 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "4480 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "4800 img procesed out of 20000, taken 1.02 sec per 1 batch\n",
      "5120 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "5440 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "5760 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "6080 img procesed out of 20000, taken 1.05 sec per 1 batch\n",
      "6400 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "6720 img procesed out of 20000, taken 1.05 sec per 1 batch\n",
      "7040 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "7360 img procesed out of 20000, taken 1.03 sec per 1 batch\n",
      "7680 img procesed out of 20000, taken 1.04 sec per 1 batch\n",
      "^C\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl-c pressed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255. Press ctrl-c to abort syncing.\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 46, in <module>\n",
      "    model.optimize_param()\n",
      "  File \"/workspace/my_cyclegan/models/semi_cycle_gan.py\", line 253, in optimize_param\n",
      "    self.backward_G()\n",
      "  File \"/workspace/my_cyclegan/models/semi_cycle_gan.py\", line 245, in backward_G\n",
      "    self.loss_depth_dif_A = self.criterionDepthRange(util.data_to_meters(self.real_depth_A, self.opt), util.data_to_meters(self.fake_depth_B, self.opt) , self.real_depth_A > -1.0).item()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --name mean_unoformstd_weights_synimg\\\n",
    "--gpu_ids 0,1\\\n",
    "--batch_size 8\\\n",
    "--disc_for_depth\\\n",
    "--use_petrain_weights\\\n",
    "--weights_dir ./checkpoints/pretrain_weights_synimg/\\\n",
    "--load_epoch_weights last\\\n",
    "--use_mean_matching\\\n",
    "--use_second_cycle\\\n",
    "--upsampling_type transpose\\\n",
    "--n_downsampling 2\\\n",
    "--ngf_depth 32\\\n",
    "--l_depth_A_begin 0\\\n",
    "--l_depth_A_end 0\\\n",
    "--l_depth_B_begin 0\\\n",
    "--l_depth_B_end 0\\\n",
    "--l_cycle_A_begin 10.0\\\n",
    "--l_cycle_A_end 10.0\\\n",
    "--l_cycle_B_begin 10.0\\\n",
    "--l_cycle_B_end 10.0\\\n",
    "--l_depth_max_iter 10000\\\n",
    "--l_identity 5.0\\\n",
    "--max_dataset_size 20000\\\n",
    "--data_shuffle\\\n",
    "--lr_D 0.0002\\\n",
    "--lr_G 0.0002\\\n",
    "--img_freq 40\\\n",
    "--loss_freq 30\\\n",
    "--save_epoch_freq 10\\\n",
    "--n_epochs 10\\\n",
    "--n_epochs_decay 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
