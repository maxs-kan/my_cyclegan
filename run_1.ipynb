{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os       \n",
    "os.chdir('/workspace/my_cyclegan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --norm instance\\\n",
    "# --init_type xavier\\\n",
    "# --num_iter_gen 1\\\n",
    "# --gan_mode lsgan\\\n",
    "# --upsampling_type transpose\\\n",
    "# --n_blocks 9\\\n",
    "# --n_downsampling 2\\\n",
    "# --ngf_depth 32\\\n",
    "# --ngf_img 32\\\n",
    "# --ndf 64\\\n",
    "# --netD n_layers\\\n",
    "# --n_layers_D 3\\\n",
    "# --continue_train\\\n",
    "# --load_epoch 6\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 14                            \t[default: 5]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "             data_shuffle: True                          \t[default: False]\n",
      "                 dataroot: /all_data/hdd/un_depth/semi/sample\n",
      "             dataset_mode: semi_cycle                    \n",
      "            deterministic: False                         \n",
      "           disc_for_depth: False                         \n",
      "         disc_for_normals: False                         \n",
      "                  dropout: False                         \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 1,2                           \t[default: 0,1]\n",
      "                 img_freq: 40                            \t[default: 1]\n",
      "                init_type: xavier                        \n",
      "           input_nc_depth: 1                             \n",
      "             input_nc_img: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "               load_epoch: last                          \n",
      "       load_epoch_weights: last                          \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "              load_size_h: 480                           \n",
      "              load_size_w: 640                           \n",
      "                loss_freq: 30                            \t[default: 1]\n",
      "                     lr_D: 0.0002                        \n",
      "                     lr_G: 0.0002                        \n",
      "                   lr_G_A: 0.0001                        \n",
      "                   lr_G_B: 0.0001                        \t[default: 0.0005]\n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: 20000                         \t[default: inf]\n",
      "             max_distance: 8000.0                        \n",
      "                    model: pretrain                      \t[default: semi_cycle_gan]\n",
      "                 n_blocks: 9                             \n",
      "           n_downsampling: 2                             \n",
      "                 n_epochs: 10                            \t[default: 1]\n",
      "           n_epochs_decay: 5                             \t[default: 1]\n",
      "               n_layers_D: 3                             \n",
      "                    n_pic: 3                             \n",
      "                     name: pretrain_weights_group        \t[default: test]\n",
      "                      ndf: 64                            \n",
      "                     netD: n_layers                      \n",
      "                ngf_depth: 32                            \n",
      "                  ngf_img: 32                            \n",
      "                     norm: group                         \t[default: instance]\n",
      "              num_workers: 4                             \n",
      "          output_nc_depth: 1                             \n",
      "            output_nc_img: 41                            \n",
      "                    phase: train                         \n",
      "          save_epoch_freq: 10                            \n",
      "          upsampling_type: transpose                     \n",
      "        use_mean_matching: False                         \n",
      "      use_petrain_weights: False                         \n",
      "         use_second_cycle: False                         \n",
      "             use_semantic: False                         \n",
      "           use_semi_cycle: False                         \n",
      "                  verbose: False                         \n",
      "              weights_dir: ./checkpoints/pretrain_weights/\n",
      "----------------- End -------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201116_145313-35xkfdop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpretrain_weights_group\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/maxs/depth_super_res\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/maxs/depth_super_res/runs/35xkfdop\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Dataset SemiCycleDataset was created\n",
      "The number of training images = 20000\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "model [PreTrainModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network netG_A] Total number of parameters : 11.620 M\n",
      "[Network netG_B] Total number of parameters : 11.620 M\n",
      "-----------------------------------------------\n",
      "560 img procesed out of 20000, taken 0.60 sec per 1 batch\n",
      "1120 img procesed out of 20000, taken 0.97 sec per 1 batch\n",
      "1680 img procesed out of 20000, taken 1.32 sec per 1 batch\n",
      "2240 img procesed out of 20000, taken 1.35 sec per 1 batch\n",
      "2800 img procesed out of 20000, taken 1.37 sec per 1 batch\n",
      "3360 img procesed out of 20000, taken 0.60 sec per 1 batch\n",
      "3920 img procesed out of 20000, taken 0.65 sec per 1 batch\n",
      "4480 img procesed out of 20000, taken 0.59 sec per 1 batch\n",
      "5040 img procesed out of 20000, taken 0.63 sec per 1 batch\n",
      "5600 img procesed out of 20000, taken 0.97 sec per 1 batch\n",
      "6160 img procesed out of 20000, taken 1.34 sec per 1 batch\n",
      "6720 img procesed out of 20000, taken 1.32 sec per 1 batch\n",
      "7280 img procesed out of 20000, taken 1.31 sec per 1 batch\n",
      "7840 img procesed out of 20000, taken 1.34 sec per 1 batch\n",
      "8400 img procesed out of 20000, taken 1.36 sec per 1 batch\n",
      "8960 img procesed out of 20000, taken 1.41 sec per 1 batch\n",
      "9520 img procesed out of 20000, taken 1.33 sec per 1 batch\n",
      "10080 img procesed out of 20000, taken 0.79 sec per 1 batch\n",
      "10640 img procesed out of 20000, taken 0.60 sec per 1 batch\n",
      "11200 img procesed out of 20000, taken 0.60 sec per 1 batch\n",
      "11760 img procesed out of 20000, taken 0.62 sec per 1 batch\n",
      "12320 img procesed out of 20000, taken 1.20 sec per 1 batch\n",
      "12880 img procesed out of 20000, taken 1.32 sec per 1 batch\n",
      "13440 img procesed out of 20000, taken 1.41 sec per 1 batch\n",
      "14000 img procesed out of 20000, taken 2.48 sec per 1 batch\n",
      "14560 img procesed out of 20000, taken 1.19 sec per 1 batch\n"
     ]
    }
   ],
   "source": [
    "!python train.py --name pretrain_weights_group\\\n",
    "--model pretrain\\\n",
    "--norm group\\\n",
    "--gpu_ids 1,2\\\n",
    "--batch_size 14\\\n",
    "--max_dataset_size 20000\\\n",
    "--data_shuffle\\\n",
    "--lr_G_A 0.0001\\\n",
    "--lr_G_B 0.0001\\\n",
    "--img_freq 40\\\n",
    "--loss_freq 30\\\n",
    "--save_epoch_freq 10\\\n",
    "--n_epochs 10\\\n",
    "--n_epochs_decay 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 8                             \t[default: 5]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "             data_shuffle: True                          \t[default: False]\n",
      "                 dataroot: /all_data/hdd/un_depth/semi/sample\n",
      "             dataset_mode: semi_cycle                    \n",
      "            deterministic: False                         \n",
      "           disc_for_depth: False                         \n",
      "         disc_for_normals: True                          \t[default: False]\n",
      "                  dropout: False                         \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0,1,2,3                       \t[default: 0,1]\n",
      "                 img_freq: 40                            \t[default: 1]\n",
      "                init_type: xavier                        \n",
      "           input_nc_depth: 1                             \n",
      "             input_nc_img: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "          l_cycle_A_begin: 10.0                          \n",
      "            l_cycle_A_end: 15.0                          \t[default: 10.0]\n",
      "          l_cycle_B_begin: 10.0                          \n",
      "            l_cycle_B_end: 15.0                          \t[default: 10.0]\n",
      "          l_depth_A_begin: 5.0                           \n",
      "            l_depth_A_end: 0.0                           \n",
      "          l_depth_B_begin: 5.0                           \n",
      "            l_depth_B_end: 0.0                           \n",
      "         l_depth_max_iter: 30000                         \t[default: 5000]\n",
      "               l_identity: 5.0                           \t[default: 0.0]\n",
      "l_reconstruction_semantic: 0.0                           \n",
      "               load_epoch: last                          \n",
      "       load_epoch_weights: last                          \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "              load_size_h: 480                           \n",
      "              load_size_w: 640                           \n",
      "                loss_freq: 30                            \t[default: 1]\n",
      "                     lr_D: 0.0002                        \n",
      "                     lr_G: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: 20000                         \t[default: inf]\n",
      "             max_distance: 8000.0                        \n",
      "                   mean_A: 1680.1208394737955            \n",
      "                   mean_B: 2781.0011373752295            \n",
      "                    model: semi_cycle_gan                \n",
      "                 n_blocks: 9                             \n",
      "           n_downsampling: 2                             \n",
      "                 n_epochs: 15                            \t[default: 1]\n",
      "           n_epochs_decay: 5                             \t[default: 1]\n",
      "               n_layers_D: 3                             \n",
      "                    n_pic: 3                             \n",
      "                     name: disc_normals_depth_range      \t[default: test]\n",
      "                      ndf: 64                            \n",
      "                     netD: n_layers                      \n",
      "                ngf_depth: 32                            \n",
      "                  ngf_img: 32                            \n",
      "                     norm: batch                         \t[default: instance]\n",
      "             num_iter_dis: 1                             \n",
      "             num_iter_gen: 1                             \n",
      "              num_workers: 4                             \n",
      "          output_nc_depth: 1                             \n",
      "            output_nc_img: 41                            \n",
      "                    phase: train                         \n",
      "          save_epoch_freq: 10                            \n",
      "                    std_A: 487.0543836544621             \n",
      "                    std_B: 780.4723869231325             \n",
      "          upsampling_type: transpose                     \n",
      "                 use_blur: False                         \n",
      "        use_mean_matching: False                         \n",
      "      use_petrain_weights: True                          \t[default: False]\n",
      "         use_second_cycle: True                          \t[default: False]\n",
      "             use_semantic: False                         \n",
      "           use_semi_cycle: False                         \n",
      "                  verbose: False                         \n",
      "              weights_dir: ./checkpoints/pretrain_weights_batch_norms/\t[default: ./checkpoints/pretrain_weights/]\n",
      "----------------- End -------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201114_200424-2qqm33g0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdisc_normals_depth_range\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/maxs/depth_super_res\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/maxs/depth_super_res/runs/2qqm33g0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "Dataset SemiCycleDataset was created\n",
      "The number of training images = 20000\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "model [SemiCycleGANModel] was created\n",
      "loading the model from ./checkpoints/pretrain_weights_batch_norms/last.pt\n",
      "loading the model from ./checkpoints/pretrain_weights_batch_norms/last.pt\n",
      "---------- Networks initialized -------------\n",
      "[Network netG_A] Total number of parameters : 11.620 M\n",
      "[Network netG_B] Total number of parameters : 11.620 M\n",
      "[Network netD_A_normal] Total number of parameters : 2.766 M\n",
      "[Network netD_B_normal] Total number of parameters : 2.766 M\n",
      "-----------------------------------------------\n",
      "320 img procesed out of 20000, taken 1.37 sec per 1 batch\n",
      "640 img procesed out of 20000, taken 1.73 sec per 1 batch\n",
      "960 img procesed out of 20000, taken 1.43 sec per 1 batch\n",
      "1280 img procesed out of 20000, taken 1.68 sec per 1 batch\n",
      "1600 img procesed out of 20000, taken 1.08 sec per 1 batch\n",
      "1920 img procesed out of 20000, taken 1.72 sec per 1 batch\n",
      "2240 img procesed out of 20000, taken 1.57 sec per 1 batch\n",
      "2560 img procesed out of 20000, taken 1.72 sec per 1 batch\n",
      "2880 img procesed out of 20000, taken 1.66 sec per 1 batch\n",
      "3200 img procesed out of 20000, taken 1.78 sec per 1 batch\n",
      "3520 img procesed out of 20000, taken 1.24 sec per 1 batch\n",
      "3840 img procesed out of 20000, taken 1.73 sec per 1 batch\n",
      "4160 img procesed out of 20000, taken 1.75 sec per 1 batch\n",
      "4480 img procesed out of 20000, taken 1.41 sec per 1 batch\n",
      "4800 img procesed out of 20000, taken 1.71 sec per 1 batch\n",
      "5120 img procesed out of 20000, taken 1.42 sec per 1 batch\n",
      "5440 img procesed out of 20000, taken 1.76 sec per 1 batch\n",
      "5760 img procesed out of 20000, taken 1.36 sec per 1 batch\n",
      "6080 img procesed out of 20000, taken 1.69 sec per 1 batch\n",
      "6400 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "6720 img procesed out of 20000, taken 1.69 sec per 1 batch\n",
      "7040 img procesed out of 20000, taken 0.95 sec per 1 batch\n",
      "7360 img procesed out of 20000, taken 1.69 sec per 1 batch\n",
      "7680 img procesed out of 20000, taken 0.80 sec per 1 batch\n",
      "8000 img procesed out of 20000, taken 3.49 sec per 1 batch\n",
      "8320 img procesed out of 20000, taken 1.70 sec per 1 batch\n",
      "8640 img procesed out of 20000, taken 1.15 sec per 1 batch\n",
      "8960 img procesed out of 20000, taken 1.68 sec per 1 batch\n",
      "9280 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "9600 img procesed out of 20000, taken 1.69 sec per 1 batch\n",
      "9920 img procesed out of 20000, taken 0.81 sec per 1 batch\n",
      "10240 img procesed out of 20000, taken 1.75 sec per 1 batch\n",
      "10560 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "10880 img procesed out of 20000, taken 1.65 sec per 1 batch\n",
      "11200 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "11520 img procesed out of 20000, taken 1.72 sec per 1 batch\n",
      "11840 img procesed out of 20000, taken 0.81 sec per 1 batch\n",
      "12160 img procesed out of 20000, taken 1.74 sec per 1 batch\n",
      "12480 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "12800 img procesed out of 20000, taken 1.74 sec per 1 batch\n",
      "13120 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "13440 img procesed out of 20000, taken 1.73 sec per 1 batch\n",
      "13760 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "14080 img procesed out of 20000, taken 1.67 sec per 1 batch\n",
      "14400 img procesed out of 20000, taken 1.69 sec per 1 batch\n",
      "14720 img procesed out of 20000, taken 1.71 sec per 1 batch\n",
      "15040 img procesed out of 20000, taken 1.67 sec per 1 batch\n",
      "15360 img procesed out of 20000, taken 1.71 sec per 1 batch\n",
      "15680 img procesed out of 20000, taken 1.60 sec per 1 batch\n",
      "16000 img procesed out of 20000, taken 1.25 sec per 1 batch\n",
      "16320 img procesed out of 20000, taken 1.74 sec per 1 batch\n",
      "16640 img procesed out of 20000, taken 1.63 sec per 1 batch\n",
      "16960 img procesed out of 20000, taken 1.64 sec per 1 batch\n",
      "17280 img procesed out of 20000, taken 1.71 sec per 1 batch\n",
      "17600 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "17920 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "18240 img procesed out of 20000, taken 0.81 sec per 1 batch\n",
      "18560 img procesed out of 20000, taken 1.70 sec per 1 batch\n",
      "18880 img procesed out of 20000, taken 1.63 sec per 1 batch\n",
      "19200 img procesed out of 20000, taken 1.66 sec per 1 batch\n",
      "19520 img procesed out of 20000, taken 1.67 sec per 1 batch\n",
      "19840 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "End of epoch 1 / 20 \t Time Taken: 3761.24 sec\n",
      "learning rate = 0.0002000\n",
      "160 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "480 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "800 img procesed out of 20000, taken 0.82 sec per 1 batch\n",
      "1120 img procesed out of 20000, taken 1.61 sec per 1 batch\n",
      "1440 img procesed out of 20000, taken 1.62 sec per 1 batch\n",
      "1760 img procesed out of 20000, taken 1.63 sec per 1 batch\n",
      "2080 img procesed out of 20000, taken 1.66 sec per 1 batch\n",
      "2400 img procesed out of 20000, taken 1.76 sec per 1 batch\n",
      "2720 img procesed out of 20000, taken 0.79 sec per 1 batch\n",
      "3040 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "3360 img procesed out of 20000, taken 0.79 sec per 1 batch\n",
      "3680 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "4000 img procesed out of 20000, taken 0.96 sec per 1 batch\n",
      "4320 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "4640 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "4960 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "5280 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "5600 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "5920 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "6240 img procesed out of 20000, taken 0.82 sec per 1 batch\n",
      "6560 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "6880 img procesed out of 20000, taken 0.75 sec per 1 batch\n",
      "7200 img procesed out of 20000, taken 0.75 sec per 1 batch\n",
      "7520 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "7840 img procesed out of 20000, taken 0.75 sec per 1 batch\n",
      "8160 img procesed out of 20000, taken 0.79 sec per 1 batch\n",
      "8480 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "8800 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "9120 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "9440 img procesed out of 20000, taken 0.75 sec per 1 batch\n",
      "9760 img procesed out of 20000, taken 0.75 sec per 1 batch\n",
      "10080 img procesed out of 20000, taken 0.80 sec per 1 batch\n",
      "10400 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "10720 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "11040 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "11360 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "11680 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "12000 img procesed out of 20000, taken 1.04 sec per 1 batch\n",
      "12320 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "12640 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "12960 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "13280 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "13600 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "13920 img procesed out of 20000, taken 0.82 sec per 1 batch\n",
      "14240 img procesed out of 20000, taken 0.77 sec per 1 batch\n",
      "14560 img procesed out of 20000, taken 0.76 sec per 1 batch\n",
      "14880 img procesed out of 20000, taken 0.76 sec per 1 batch\n"
     ]
    }
   ],
   "source": [
    "!python train.py --name disc_normals_depth_range\\\n",
    "--gpu_ids 0,1,2,3\\\n",
    "--batch_size 8\\\n",
    "--disc_for_normals\\\n",
    "--norm batch\\\n",
    "--use_petrain_weights\\\n",
    "--weights_dir ./checkpoints/pretrain_weights_batch_norms/\\\n",
    "--load_epoch_weights last\\\n",
    "--use_second_cycle\\\n",
    "--l_depth_A_begin 5\\\n",
    "--l_depth_A_end 0\\\n",
    "--l_depth_B_begin 5\\\n",
    "--l_depth_B_end 0\\\n",
    "--l_cycle_A_begin 10.0\\\n",
    "--l_cycle_A_end 15.0\\\n",
    "--l_cycle_B_begin 10.0\\\n",
    "--l_cycle_B_end 15.0\\\n",
    "--l_depth_max_iter 30000\\\n",
    "--l_identity 5.0\\\n",
    "--max_dataset_size 20000\\\n",
    "--data_shuffle\\\n",
    "--lr_D 0.0002\\\n",
    "--lr_G 0.0002\\\n",
    "--img_freq 40\\\n",
    "--loss_freq 30\\\n",
    "--save_epoch_freq 10\\\n",
    "--n_epochs 15\\\n",
    "--n_epochs_decay 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
